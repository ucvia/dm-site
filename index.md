---
layout: default
---

# Aprendizaje Automático [6561] - II 2023

**Instructor**: [Fernando Crema García](https://ml.ucv.ai/contacto)

Por favor, si me escriben un email, usen como preámbulo [UCV][6561]

**Preparadores**: TBD.

---
<a href="https://en.wikipedia.org/wiki/George_E._P._Box"> <img class="profile-picture" src="/static/box.jpg"> </a>

> **All models are wrong but some are useful** <br> George Box 


1. [Anuncios](#anuncios)
2. [Evaluaciones](#evaluaciones)
3. [Calendario](#calendario)
4. [Código de Honor](#código-de-honor)
5. [Referencias](#referencias)

# Anuncios <a href="#"><button class="btn" ><i class="fa fa-home"></i> </button></a>


1. **[18/11/2023]** <span style="color:rgb(134, 38, 51)">**[Evaluación]**</span> Fecha de examen parcial 1 acordada para el 15/12/2023
2. **[18/11/2023]** Disponible clase trade off bias-variance.
3. **[17/11/2023]** Publicadas fechas de evaluaciones.
4. **[15/11/2023]** <span style="color:rgb(134, 38, 51)">**[Evaluación]**</span> Publicada evaluación de Python del laboratorio 1 con Notebook de ejemplo.
5. **[14/11/2023]** Disponible laboratorio de Docker, Docker-Compose y Flask.
6. **[14/11/2023]** Agregadas clases anteriores previas a Regresión Logística.
7. **[13/11/2023]** Agregado notebook de clase de regularización.
8. **[13/11/2023]** Agregadas referencias sobre Álgebra Lineal
9. **[13/11/2023]** Publicada la página de la materia!

# Evaluaciones <a href="#"><button class="btn" ><i class="fa fa-home"></i> </button></a>

Tareas y asignaciones | Exámenes | Proyectos | Total
:--------:|:-------:|:-------:|:--------:
30% | 40% | 30% | 100%

## Proyecto

| | Grupos A | Grupos B |
:---------:|:--------:|:-------:|
**Fecha** | 19/02/2024 | 23/02/2024
**Asignados** | Por definir | Por definir 

## Exámenes teóricos

 | | Examen 1 | Examen 2|
:---------:|:--------:|:-------:|
**Fecha** | 15/12/2023|09/02/2024
**Temas** |  Tema 1, Tema 2, Tema 3 y Tema 6 (para regresión y clasificación). | Todos

## Asignaciones

### 1. Regresión, clasificación y Python

1. La parte de Python del laboratorio evaluado 1 está disponible en [01_Tarea Python](https://ml.ucv.ai/tareas/01_Tarea_Python.pdf "download") y el [Notebook base](https://ml.ucv.ai/notebooks/00_Template_Tarea.ipynb "download") explicado en el enunciado.

# Calendario <a href="#"><button class="btn" ><i class="fa fa-home"></i> </button></a>

Fecha | Tema | Material | Nota | Acuerdos
:-----:|-------|:--------:|--------|--------
17/11/23 | El tradeoff _bias-variance_ (sesgo vs. varianza). | [04_Tradeoff Bias-Variance](https://ml.ucv.ai/notebooks/04_Bias_Variance_Tradeoff.ipynb "download") | Sección 2.1.3 de [ISLP] | Acordada fecha examen parcial para el 15/12/2023.
13/11/23 | Introducción a métodos de regularización: Lasso y Ridge. | [03_Regularización](https://ml.ucv.ai/notebooks/03_Regularizacion.ipynb "download") | Versión b.1 | Tarea debe ser cambiada.
10/11/23 | Regresión Logística | [02_Regresión Logística](https://ml.ucv.ai/notebooks/02_Logistic_Regression.ipynb "download") | Enviado notebook a los alumnos | A partir de esta clase compartimos todo via Notebooks.
01/11/23 |Laboratorio Docker, Docker-Compose y Flask|[Repositorio Laboratorio](https://github.com/ucvia/ml-lab00-python-docker.git)| Usaremos este stack en el **proyecto**, pueden cambiar [Flask](https://flask.palletsprojects.com/en/3.0.x/) por [FastAPI](https://fastapi.tiangolo.com/) |
31/10/23 | Cálculos en clase sobre ecuaciones normales| [01_Regresión cálculos completos](https://ml.ucv.ai/clases/01_Regresion_tarea3_calculos_completos.pdf) | El pdf está anotado por mí luego de clase (comentarios en cada paso)|  
28/10/23 | Derivando solución de Regresión Lineal | [01_Regresión solución](https://ml.ucv.ai/clases/01_Regresion_Solucion.pdf "download")| Clase donde derivamos haciendo repaso de álgebra lineal | El 21 de octubre íbamos a derivar la solución.
23/10/23 | Introducción a Regresión Lineal | [01_Regresión introducción](https://ml.ucv.ai/clases/01_Regresion_Introduccion.pdf "download") | **Tarea**: Derivar ecuaciones normales. | 
20/10/23 | Aprendizaje Supervisado y Modelos Clásicos | [00_Aprendizaje supervisado](https://ml.ucv.ai/clases/00_Aprendizaje_Supervisado.pdf "download") | | 
16/10/23 |Introducción: Inteligencia | [00_Aprendizaje supervisado](https://ml.ucv.ai/clases/00_Introduccion_Clase_Inteligencia.pdf "download")| **Tarea:** Leer [paper](https://academic.oup.com/mind/article/LIX/236/433/986238) de Alan Turing <br> [Video de Francois Chollet](https://www.youtube.com/watch?v=oD54vJlG-S4) |

# Código de honor <a href="#"><button class="btn" ><i class="fa fa-home"></i> </button></a>

<img class="profile-picture" src="/static/thanos.jpeg">

Pueden (y aliento fírmemente) discutir con otros estudiantes del curso sobre los proyectos y laboratorios. Sin embargo, debe entender bien sus soluciones y cada entregable debe ser personal o grupal, de tal manera que esté escrito de forma aislada. 

El grupo docente se reserva el derecho de interrogar sobre laboratorios, exámenes y proyectos.

Qué podemos hacer?

1. Discutir cómo implementar un algoritmo.
2. Qué tipo de bibliotecas usar?
3. Cómo puedo instalar un framework? 

## Uso de internet

También puedes consultar Internet para obtener información, siempre que no revele la solución. Si una pregunta te pide que diseñes e implementes un algoritmo para un problema, está bien si encuentras información sobre cómo resolver un problema pero no está bien si buscas el código o el algoritmo para el problema que te están preguntando. 

## Proyectos

Para los proyectos, puedes hablar con otros alumnos del curso sobre dudas sobre el lenguaje de programación, librerías, algún tema de API, etcétera, pero tanto las soluciones como la programación deben ser tuyas. 

## Uso de LLM

Lo mismo se aplica a las herramientas de IA generativa, como ChatGPT, Bard, Bing, etc. Estas pueden ser herramientas útiles en tu trabajo. Sin embargo, el uso de dichas herramientas cuando no esté explícitamente permitido será tratado como **plagio** y está **estrictamente** prohibido.

Cualquier duda pueden contactar al grupo docente.

# Referencias <a href="#"><button class="btn" ><i class="fa fa-home"></i> </button></a>

Cualquier elemento de las referencias usado en una clase será referenciado con [Nombre-Referencia]

## Álgebra Lineal

* [Kolter](http://www.cs.cmu.edu/~zkolter/course/linalg/index.html) Repaso de Álgebra Lineal de J. Zico Kolter
* [Strang-MOOC](https://ocw.mit.edu/courses/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/) Curso online Matrix Methods In Data Analysis, Signal Processing, And Machine Learning basado en [Strang-Data]
* [Strang-Data](https://math.mit.edu/~gs/learningfromdata/) Linear Algebra and Learning from Data (2019)
by Gilbert Strang   (gilstrang@gmail.com)  ISBN 13: 978-06921963-8-0

## Matemática para Aprendizaje Automático

* [MML](https://mml-book.github.io/) Mathematics for Machine Learning by Marc Peter Deisenroth, A. Aldo Faisal, and Cheng Soon Ong.  Este libro tiene mucho más contenido que el que vamos a necesitar pero los capítulos 2, 3, 4 y 5 son los capítulos útiles para nosotros.
* [WASS](https://www.stat.cmu.edu/~larry/all-of-statistics/) All of Statistics - Larry Wasserman. Por si quieren repasar teoría de probabilidades y estadística.

## Aprendizaje Automático

* [ISLP](https://www.statlearning.com/) An Introduction to Statistical Learning with Python by Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani, Jonathan Taylor. ISBN-13 978-3031387463. En especial la versión de Python.